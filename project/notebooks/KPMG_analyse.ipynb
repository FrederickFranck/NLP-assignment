{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPMG analyse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!python -m spacy download nl_core_news_md\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load model\n",
    "nlp = spacy.load(\"nl_core_news_md\")\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some debugging stuff\n",
    "# \n",
    "if DEBUG:\n",
    "    import inspect \n",
    "    def getname():\n",
    "        import sys\n",
    "        return sys._getframe(1).f_code.co_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_cleanandlemmatize(txtdoc: str, list_wordstoskip:str = '', onlynouns:bool = True) -> (dict,list):\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "   \n",
    "    LANG='nl'\n",
    "    # words to discard\n",
    "    months={'nl':['januari','februari','maart','april','mei','juni','augustus','september','oktober','november','december'],\n",
    "            'fr':['janvier','fevrier','mars','avril','mai','juin','juillet','aout','septembre','octobre','decembre']}\n",
    "    days={'nl':['maandag','dinsdag','woensdag','donderdag','vrijdag','zaterdag','zondag'],\n",
    "            'fr':['lundi','mardi','mercredi','jeudi','vendredi','samedi','dimanche']}\n",
    "    # \n",
    "    nlp.max_length=10000000\n",
    "    nlp_doc=nlp(txtdoc)\n",
    "    list_allwordslemmatized=[]\n",
    "    dict_uniqwords={}\n",
    "    list_tokens=[]\n",
    "    #filter\n",
    "    for token in nlp_doc:\n",
    "        lemma_lower=token.lemma_.lower()\n",
    "        if token in stopwords:\n",
    "            continue\n",
    "        if (token.is_punct or token.is_space or token.is_stop):\n",
    "            continue\n",
    "        if token.text.isdecimal():\n",
    "            continue\n",
    "        if True in [char.isdigit() for char in token.text]:\n",
    "            continue\n",
    "        if token.text[-1] == '.':\n",
    "            continue\n",
    "        if len(token.text) <= 2:\n",
    "            continue\n",
    "        if lemma_lower in months[LANG]:\n",
    "            continue\n",
    "        if lemma_lower in days[LANG]:\n",
    "            continue\n",
    "        if lemma_lower in list_wordstoskip:\n",
    "            continue\n",
    "        #pass only nouns\n",
    "        if token.pos_ != 'NOUN':\n",
    "            continue\n",
    "        #create dict of unique words with count\n",
    "        if lemma_lower not in dict_uniqwords: \n",
    "            dict_uniqwords[lemma_lower]=1\n",
    "            #save tokens for vector comparison\n",
    "            list_tokens.append(token)\n",
    "        else:\n",
    "            dict_uniqwords[lemma_lower]+=1\n",
    "    return dict_uniqwords, list_tokens\n",
    "    #end of filter------------------------\n",
    "\n",
    "#compare a token against a tokenslist\n",
    "def token_compare(token_totest,list_tokens,min_score:int = 0.6):\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "    \n",
    "    #return list of tokens with similarity >= min_score \n",
    "    list_tokens_toreturn=[]\n",
    "    tot_similar_word=0\n",
    "    istax=False\n",
    "    for token in list_tokens:\n",
    "        similar=token_totest.similarity(token)\n",
    "        #only addup the scores >= min_score\n",
    "        if similar >= min_score:\n",
    "            list_tokens_toreturn.append([token_totest,token,similar])\n",
    "            #positive for tax\n",
    "            istax=True\n",
    "            tot_similar_word+=similar\n",
    "    return istax, tot_similar_word, list_tokens_toreturn\n",
    "\n",
    "def createlistofkeywords(numberofdocumenttoscan:int = 50,similar_doc:int = 0,min_score:float = 0.6, list_keywords:list = []) -> (list,list,list):\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "     \n",
    "    list_keep_tax_words=[]\n",
    "    list_keep_pointer_taxdocs=[]\n",
    "    list_keep_pointer_alldocs=[]\n",
    "\n",
    "    #take all docs if 0\n",
    "    if numberofdocumenttoscan == 0:\n",
    "        numberofdocumenttoscan=len(df)\n",
    "    \n",
    "    for n in range(numberofdocumenttoscan):\n",
    "\n",
    "        print(\"Documents analyzed: \",numberofdocumenttoscan,n)\n",
    "\n",
    "        txtdoc = df['cleantextnl'].values[n]\n",
    "        list_wordstoskip=['blabla','blablabla'] #add here words to discard\n",
    "        dict_uniqwords,list_tokens=nlp_cleanandlemmatize(txtdoc,list_wordstoskip) #get tokens\n",
    "\n",
    "        #tokenize and check\n",
    "        tot_similar_doc=0     #keep score for onlytax docs (istax=True)\n",
    "        tot_similar_doc_all=0 #keep score for all docs\n",
    "        istax_doc=False\n",
    "        \n",
    "        for word in list_keywords:\n",
    "            token_word = nlp(word)\n",
    "            istax, tot_similar_word, list_res_tokens=token_compare(token_word,list_tokens,min_score)\n",
    "            #if DEBUG: print(\"DEBUG\",istax, tot_similar_word, list_res_tokens)\n",
    "            tot_similar_doc_all+=tot_similar_word\n",
    "\n",
    "            if istax:\n",
    "                for taxtoken in list_res_tokens:\n",
    "                    if taxtoken[1].lemma_.lower() not in list_keep_tax_words:\n",
    "                        list_keep_tax_words.append(taxtoken[1].lemma_.lower())\n",
    "                tot_similar_doc+=tot_similar_word\n",
    "            istax_doc |= istax\n",
    "\n",
    "        #store score for all\n",
    "        list_keep_pointer_alldocs.append([n,tot_similar_doc_all])\n",
    "\n",
    "        #store score for taxdocs\n",
    "        if istax_doc and (tot_similar_doc >= similar_doc):\n",
    "            list_keep_pointer_taxdocs.append([n,tot_similar_doc])\n",
    "\n",
    "    return list_keep_pointer_taxdocs, list_keep_tax_words, list_keep_pointer_alldocs\n",
    "\n",
    "def create_pickle_keywords_and_docscores(list_keywords:list = ['belasting'], file_keywords:str = \"\", file_docscores:str = \"\")-> (list,list):\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "     \n",
    "    #settings : [numberofdocumenttoscan (0 for all), min similarity score for doc to get into the taxlist, min similarity score for keywords]):\n",
    "    settings=[  [5,5,0.97],    #step1\n",
    "                [10,10,0.95],  #step2\n",
    "                [15,20,0.90],  #step3\n",
    "                [0,40,0.87]    #step4 All documents\n",
    "                ]\n",
    "    \n",
    "    numberofsteps=len(settings)\n",
    "    for step in range(numberofsteps):\n",
    "        list_keep_pointer_taxdocs , list_keep_tax_words, list_keep_pointer_alldocs = createlistofkeywords(settings[step][0],settings[step][1],settings[step][2],list_keywords)\n",
    "        list_keywords+=list_keep_tax_words\n",
    "        #no duplicates\n",
    "        list_keywords = list(set(list_keywords))\n",
    "        list_docscores=list_keep_pointer_alldocs\n",
    "        \n",
    "        # no file no pickle\n",
    "        if file_keywords != \"\" :\n",
    "            df_keywords=pd.DataFrame(list_keywords,columns=['keywords'])\n",
    "            df_keywords.to_pickle(file_keywords)  \n",
    "            \n",
    "        if file_docscores != \"\"  :\n",
    "            df_docscores=pd.DataFrame(list_keep_pointer_alldocs,columns=['docpointer','docscores']) \n",
    "            df_docscores.to_pickle(file_docscores)  \n",
    "\n",
    "    return list_keywords, list_docscores\n",
    "\n",
    "def score_text(txt:str,language:str = 'nl', min_score:float = 0.3, file_keywords:str = \"../data/tax_keywords_nl.pkl\") -> float :\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "\n",
    "    if language == 'nl':\n",
    "        df_keywords = pd.read_pickle(file_keywords) \n",
    "        list_keywords=list(df_keywords['keywords'])\n",
    "        \n",
    "        #clean txt / get tokens\n",
    "        dict_uniqwords,list_tokens=nlp_cleanandlemmatize(txt,[]) \n",
    "        \n",
    "        docscore=0  \n",
    "        for word in list_keywords:\n",
    "            token_word = nlp(word)\n",
    "            for token in list_tokens:\n",
    "                similar=token_word.similarity(token)\n",
    "                #similarity > min_score to be taken into account\n",
    "                if similar >= min_score:\n",
    "                    docscore+=similar\n",
    "    else:\n",
    "        print(\"Language selection not supported for now!\")\n",
    "\n",
    "    return docscore\n",
    "\n",
    "def create_initial_keywordlist(language:str ='nl') -> None:\n",
    "    # create keyword list picklefile and docscores picklefile\n",
    "    #read all docs\n",
    "    global df\n",
    "    df = pd.read_pickle(\"../data/Staatsblad_nl_fr.pkl\") \n",
    "    if language == 'nl':\n",
    "        #start search for nl keywords\n",
    "        keywords, docscores = create_pickle_keywords_and_docscores(['belasting','tax','fisc'], \"../data/tax_keywords_nl.pkl\", \"../data/tax_docscores_nl.pkl\")\n",
    "    else:\n",
    "        print(\"Language selection not supported for now!\")\n",
    "\n",
    "\n",
    "#unsupervised keyword search\n",
    "def get_keywordsunsupervised(txt:str, sim:float = 0.90) -> dict:\n",
    "    # input a text \n",
    "    # output relevant keywords\n",
    "    doc = nlp(txt)\n",
    "\n",
    "    chnk=[]\n",
    "    for chunk in doc.noun_chunks:\n",
    "        chnk.append(chunk)\n",
    "\n",
    "    sim_low=sim\n",
    "    txt_keywords=''\n",
    "    list_keywordswithscores=[]\n",
    "    for c in chnk:\n",
    "        word_simil=0\n",
    "        for t in chnk:\n",
    "            simil=c.similarity(t)\n",
    "            if (simil >= sim_low and simil < 1): \n",
    "                word_simil+=simil\n",
    "                \n",
    "        if word_simil > 1:\n",
    "            list_keywordswithscores.append([c,word_simil])\n",
    "            txt_keywords=txt_keywords + c.lemma_ +' '\n",
    "            \n",
    "    dict_txt,list_tokens=nlp_cleanandlemmatize(txtdoc=txt_keywords,list_wordstoskip='',onlynouns=True)\n",
    "    return dict_txt\n",
    "\n",
    "def score_topic_list(txt:str,language:str = 'nl', min_score:float = 0.3, list_topics:list = ['belasting','tax']) -> float :\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "\n",
    "    if language == 'nl':\n",
    "       \n",
    "        #clean txt / get tokens\n",
    "        dict_uniqwords,list_tokens=nlp_cleanandlemmatize(txt,[]) \n",
    "\n",
    "        topic_score=[]\n",
    "       \n",
    "        for word in list_topics:\n",
    "            docscore=0\n",
    "            token_word = nlp(word)\n",
    "            for token in list_tokens:\n",
    "                similar=token_word.similarity(token)\n",
    "                #similarity > min_score to be taken into account\n",
    "                #print(similar)\n",
    "                if similar >= min_score:\n",
    "                    docscore+=similar\n",
    "            topic_score.append(docscore)\n",
    "            #print(\"@@@\",word,docscore)\n",
    "    else:\n",
    "        topic_score=[]\n",
    "        print(\"Language selection not supported for now!\")\n",
    "\n",
    "    return topic_score   \n",
    "\n",
    "\n",
    "def score_text_byvector(txt:str,language:str = 'nl', min_score:float = 0.3, file_keywords:str = \"../data/tax_keywords_nl.pkl\") -> float :\n",
    "    if language != 'nl':\n",
    "        print(\"Language selection not supported for now!\")\n",
    "        return -999\n",
    "\n",
    "    df_keywords = pd.read_pickle(file_keywords) \n",
    "    list_keywords=list(df_keywords['keywords'])\n",
    "\n",
    "    txt_keywords=''\n",
    "    for t in list_keywords: txt_keywords += ' ' + t\n",
    "    token_txt = nlp(txt_keywords)\n",
    "\n",
    "    #clean txt  \n",
    "    txt_doc=''\n",
    "    dict_uniqwords,list_tokens=nlp_cleanandlemmatize(txt,[]) \n",
    "    for i in list_tokens: txt_doc += ' ' + (i.lemma_).lower()\n",
    "    token_doc = nlp(txt_doc)\n",
    "\n",
    "    docscore=token_doc.similarity(token_txt)   \n",
    "\n",
    "    return docscore\n",
    "\n",
    "\n",
    "def get_topic_byvector(txt:str, language:str = 'nl') -> [float,str] :\n",
    "    if language != 'nl':\n",
    "        print(\"Language selection not supported for now!\")\n",
    "        return -999\n",
    "    list_topic_keywords = [ ['inkomstenbelasting'],\n",
    "                            ['personenbelasting'],\n",
    "                            ['vennootschapsbelasting'],\n",
    "                            ['rechtspersonenbelasting'],\n",
    "                            ['belasting van niet-inwoners'],\n",
    "                            ['belasting op de toegevoegde waarde'],\n",
    "                            ['internationale belastingrecht'],\n",
    "                            ['registratierechten'],\n",
    "                            ['successierechten'],\n",
    "                            ['douanerechten'],\n",
    "                            ['verkeersbelasting'],\n",
    "                            ['loonbelasting'],\n",
    "                            ['dividendbelasting'],\n",
    "                            ['erfbelasting'],\n",
    "                            ['schenkbelasting'],\n",
    "                            ['kansspelbelasting'],\n",
    "                            ['gokbelasting'],\n",
    "                            ['vermogensrendementsheffing']\n",
    "                            ]\n",
    "\n",
    "\n",
    "    #clean text  \n",
    "    txt_doc=''\n",
    "    dict_uniqwords,list_tokens=nlp_cleanandlemmatize(txt,[]) \n",
    "    for i in list_tokens: txt_doc += ' ' + (i.lemma_).lower()\n",
    "\n",
    "    #\n",
    "    topicscore=[]\n",
    "    for list_keywords in list_topic_keywords:\n",
    "        txt_keywords=''\n",
    "        for t in list_keywords: txt_keywords += ' ' + t\n",
    "        token_txt = nlp(txt_keywords)\n",
    "        token_doc = nlp(txt_doc)\n",
    "\n",
    "        topicscore.append([token_doc.similarity(token_txt),list_keywords])   \n",
    "        topicscore.sort(reverse=True)\n",
    "        score = topicscore[0]\n",
    "    return score\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create the inital keyword list (takes some time to run +-7min on my old laptop) and needs to be run only once!\n",
    "#df = pd.read_pickle(\"../data/Staatsblad_nl_fr.pkl\") \n",
    "\n",
    "#create_initial_keywordlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmadmin\\AppData\\Local\\Temp\\ipykernel_1140\\2859718403.py:294: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  topicscore.append([token_doc.similarity(token_txt),list_keywords])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc. nr: 0  --->>  [0.7487207824085366, ['vennootschapsbelasting']]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 1  --->>  [0.6901101525735599, ['successierechten']]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 2  --->>  [0.4549312785212403, ['registratierechten']]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 3  --->>  [0.7398864433592595, ['internationale belastingrecht']]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 4  --->>  [0.7552442384831771, ['vennootschapsbelasting']]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 5  --->>  [0.7532072980154575, ['vennootschapsbelasting']]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 6  --->>  [0.7793690473749172, ['vermogensrendementsheffing']]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 7  --->>  [0.7524580376003799, ['internationale belastingrecht']]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 8  --->>  [0.7162664326227041, ['vennootschapsbelasting']]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 9  --->>  [0.6321006821287842, ['vennootschapsbelasting']]\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Example usage for get_topic_byvector\n",
    "df = pd.read_pickle(\"../data/Staatsblad.pkl\") \n",
    "\n",
    "for loop in range(10):\n",
    "    txt=df['cleantextnl'][loop]\n",
    "    topicscore=get_topic_byvector(txt)\n",
    "\n",
    "    #topic.sort(reverse=True)\n",
    "    print(\"Doc. nr:\",loop,\" --->> \",topicscore)\n",
    "    print('------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for d: 2.9043948372239012 score for d2: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmadmin\\AppData\\Local\\Temp\\ipykernel_8804\\257392022.py:157: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  similar=token_word.similarity(token)\n"
     ]
    }
   ],
   "source": [
    "#Get score for one txt string\n",
    "#############################\n",
    "#This will use the pickled keyword list created by the create_initial_keywordlist() function\n",
    "txt='de belastingen zijn er weer\\n Deze tax keer meer belastingen en meer tax te betalen!\\n meer en meer belastingen tax is nodig en fisc'\n",
    "txt2='this text does not contain any ... related words\\n '\n",
    "d = score_text(txt)\n",
    "d2 = score_text(txt2)\n",
    "print(\"score for d:\",d,\"score for d2:\",d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmadmin\\AppData\\Local\\Temp\\ipykernel_8804\\782965930.py:219: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  similar=token_word.similarity(token)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20.797576331427283, 'vennootschapsbelasting')\n",
      "(10.702925898996895, 'successierechten')\n",
      "(12.932751534976378, 'registratierechten')\n",
      "(20.9291968132176, 'internationale belastingrecht')\n",
      "(15.127752742486264, 'vennootschapsbelasting')\n",
      "(10.571855618677969, 'vennootschapsbelasting')\n",
      "(83.10764506730264, 'successierechten')\n",
      "(21.81420090009421, 'internationale belastingrecht')\n",
      "(12.927745560924786, 'vennootschapsbelasting')\n",
      "(12.927745560924786, 'vennootschapsbelasting')\n",
      "(4.606601795191464, 'vennootschapsbelasting')\n",
      "(39.71346430634192, 'successierechten')\n",
      "(24.621960825340512, 'successierechten')\n",
      "(6.807182539653486, 'registratierechten')\n",
      "(20.127441643780777, 'vennootschapsbelasting')\n",
      "(31.355287047152935, 'vennootschapsbelasting')\n",
      "(33.43220662498416, 'internationale belastingrecht')\n",
      "(6.064743018773677, 'inkomstenbelasting')\n",
      "(3.9201014971712604, 'vennootschapsbelasting')\n",
      "(9.630507982377221, 'inkomstenbelasting')\n",
      "(5.014051644103372, 'vennootschapsbelasting')\n",
      "(6.968780967554487, 'successierechten')\n",
      "(6.356477653025872, 'inkomstenbelasting')\n",
      "(5.2375128364451875, 'vennootschapsbelasting')\n",
      "(14.069775203140292, 'vennootschapsbelasting')\n",
      "(42.537304010329194, 'vennootschapsbelasting')\n",
      "(35.858935326491824, 'vennootschapsbelasting')\n",
      "(42.94708223383438, 'internationale belastingrecht')\n",
      "(42.58939724543896, 'internationale belastingrecht')\n",
      "(18.26464341598651, 'inkomstenbelasting')\n",
      "(23.921136219136084, 'inkomstenbelasting')\n",
      "(78.76330683692736, 'internationale belastingrecht')\n",
      "(81.92282263445101, 'successierechten')\n",
      "(81.48536920243413, 'successierechten')\n",
      "(81.84405477544361, 'successierechten')\n",
      "(79.51153042028365, 'successierechten')\n",
      "(58.38146891440886, 'internationale belastingrecht')\n",
      "(82.50171602225741, 'successierechten')\n",
      "(78.12489602265228, 'successierechten')\n",
      "(28.542655512568512, 'internationale belastingrecht')\n",
      "(28.542655512568512, 'internationale belastingrecht')\n",
      "(70.12900114572597, 'internationale belastingrecht')\n",
      "(42.91915816802924, 'successierechten')\n",
      "(28.542655512568512, 'internationale belastingrecht')\n",
      "(70.12900114572597, 'internationale belastingrecht')\n",
      "(42.91915816802924, 'successierechten')\n",
      "(28.542655512568512, 'internationale belastingrecht')\n",
      "(70.12900114572597, 'internationale belastingrecht')\n",
      "(42.91915816802924, 'successierechten')\n",
      "(70.07103062537425, 'successierechten')\n",
      "(60.45886327849998, 'internationale belastingrecht')\n",
      "(70.07103062537425, 'successierechten')\n",
      "(6.844948720267265, 'vennootschapsbelasting')\n",
      "(38.234937348455894, 'vennootschapsbelasting')\n",
      "(66.39457079825736, 'successierechten')\n",
      "(162.4596209816619, 'successierechten')\n",
      "(105.9500301050628, 'successierechten')\n",
      "(40.41616531304666, 'successierechten')\n",
      "(12.33195206534126, 'registratierechten')\n",
      "(11.871024604467925, 'successierechten')\n",
      "(12.025944649584613, 'successierechten')\n",
      "(164.04279921219202, 'successierechten')\n",
      "(119.46220930416804, 'successierechten')\n",
      "(6.177718114309285, 'vennootschapsbelasting')\n",
      "(16.570424245032154, 'vennootschapsbelasting')\n",
      "(22.85378132317281, 'successierechten')\n",
      "(8.731842480204316, 'vennootschapsbelasting')\n",
      "(35.28435286054574, 'successierechten')\n",
      "(52.730708328411176, 'successierechten')\n",
      "(65.27834431262738, 'internationale belastingrecht')\n",
      "(82.1633056804766, 'successierechten')\n",
      "(29.78429718020919, 'successierechten')\n",
      "(125.72769397349921, 'successierechten')\n",
      "(115.95019340711698, 'successierechten')\n",
      "(52.16119594187043, 'internationale belastingrecht')\n",
      "(59.336944472064665, 'successierechten')\n",
      "(36.17204430348845, 'successierechten')\n",
      "(31.683711198198864, 'internationale belastingrecht')\n",
      "(34.26554793007094, 'successierechten')\n",
      "(84.01378170133017, 'successierechten')\n",
      "(61.05531081531946, 'successierechten')\n",
      "(25.59094351802751, 'internationale belastingrecht')\n",
      "(28.638023745860377, 'internationale belastingrecht')\n",
      "(30.128684941892786, 'registratierechten')\n",
      "(62.89495876720668, 'successierechten')\n",
      "(94.40741329689854, 'successierechten')\n",
      "(63.89247958330342, 'successierechten')\n",
      "(211.8779789425709, 'successierechten')\n",
      "(64.00615280090359, 'successierechten')\n",
      "(48.76001922187781, 'successierechten')\n",
      "(43.658176804663874, 'successierechten')\n",
      "(37.916038300646015, 'successierechten')\n",
      "(73.54319141050769, 'internationale belastingrecht')\n",
      "(92.56885791947582, 'successierechten')\n",
      "(54.64228824237762, 'internationale belastingrecht')\n",
      "(99.86269207677826, 'successierechten')\n",
      "(108.68459617204583, 'successierechten')\n",
      "(83.57164295765347, 'successierechten')\n",
      "(74.55531822365238, 'successierechten')\n",
      "(17.899997557451645, 'registratierechten')\n"
     ]
    }
   ],
   "source": [
    "#GETSCORE FOR THE DIFFERENT TYPES OF TAXES\n",
    "#\n",
    "# soorten belastingen\n",
    "def get_topic(txt:str ,topic:list = ['inkomstenbelasting',\n",
    "                'personenbelasting',\n",
    "                'vennootschapsbelasting',\n",
    "                'rechtspersonenbelasting',\n",
    "                'belasting van niet-inwoners',\n",
    "                'belasting op de toegevoegde waarde',\n",
    "                'internationale belastingrecht',\n",
    "                'registratierechten',\n",
    "                'successierechten',\n",
    "                'douanerechten',\n",
    "                'verkeersbelasting',\n",
    "                'loonbelasting',\n",
    "                'dividendbelasting',\n",
    "                'erfbelasting',\n",
    "                'schenkbelasting',\n",
    "                'kansspelbelasting',\n",
    "                'gokbelasting',\n",
    "                'vermogensrendementsheffing'\n",
    "                ]) -> list:\n",
    "    \n",
    "    score=score_topic_list(txt,'nl',0.001,topic)\n",
    "    maxscore = 0\n",
    "    for i in range(len(topic)) :\n",
    "        #print(type_of_taxes[i], score[i])\n",
    "        if score[i] > maxscore : \n",
    "            maxscore = score[i]\n",
    "            maxtopic=topic[i]    \n",
    "\n",
    "    return maxscore, maxtopic\n",
    "\n",
    "#test\n",
    "stop=100\n",
    "for txt in df['cleantextnl']:\n",
    "    maxx = get_topic(txt)\n",
    "    print(maxx)\n",
    "    if stop == 1: \n",
    "        break\n",
    "    stop+=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC DOC 0:{'houdbaarheidsdatum': 2, 'bewoner': 1, 'applicatie': 1, 'medewerker': 1, 'koffiekoek': 1, 'reactie': 1, 'overschot': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmadmin\\AppData\\Local\\Temp\\ipykernel_8804\\257392022.py:194: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  simil=c.similarity(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'onder_wijswetgeving': 1, 'onderwijs': 9, 'artikel': 3, 'regering': 12, 'voorwaarde': 3, 'organisatie': 8, 'onderwijsactiviteit': 2, 'studie': 7, 'type': 7, 'inspecteur': 1, 'akkoordbevinding': 1, 'minister': 2, 'lid': 17, 'wet': 1, 'opschorting': 1, 'noodzakelijkheid': 3, 'vast_stellen': 1, 'maatregel': 3, 'aandacht': 1, 'instelling': 5, 'omzendbrief': 2, 'nummer': 1, 'aanneming': 1, 'voordracht': 1, 'gezondheidscrisis': 1, 'regeling': 2, 'student': 7, 'onderwijseenheden': 1, 'einddatum': 1, 'eenheid': 1, 'lesti_jd': 1, 'lestijd': 1, 'punt': 1, 'ond_erwijswetgeving': 1, 'herinsc_hrijving': 1, 'onderwijseenhed': 1, 'opsluiting': 1, 'zitting': 3, 'onderwijsinstelling': 2, 'paragraaf': 1, 'evaluatie': 8, 'leerresultaten': 3, 'directie': 2, 'toelating': 2, 'lee_rresultat': 2, 'nazicht': 2, 'onderwijseenheid': 2, 'regel': 3, 'plan': 1, 'evaluatiedatum': 1, 'aard': 1, 'kenmerk': 1, 'materieel': 1, 'omstandigheid': 1, 'mededeling': 1, 'beoordeling': 1, 'eindevaluatie': 2, 'begind_atum': 3, 'startdatum': 1, 'certificatie': 2, 'noemen': 1, 'uitvoering': 1}\n",
      "-----------------------\n",
      "{'steun': 1, 'ziekenhuis': 12, 'artikel': 5, 'financiering': 1, 'dienst': 1, 'regering': 7, 'inspecteur': 1, 'akkoordbevinding': 1, 'minister': 6, 'beleid_lijnen': 1, 'verspreiding': 1, 'bevoegdheid': 2, 'gevolg': 1, 'decreet': 1, 'uitoefening': 1, 'oprichting': 2, 'toename': 1, 'afdeling': 2, 'organisatie': 1, 'opname': 1, 'mobilisatie': 1, 'noodzaak': 1, 'bestrijding': 1, 'voordracht': 1, 'ziekenhuizen': 1, 'voorwaarde': 2, 'toekenning': 2, 'opdracht': 1, 'uitgave': 1, 'inrichting': 1, 'aanpassing': 1, 'opvang': 2, 'ziekenhuisopname': 2, 'aankoop': 1, 'uit_rusting': 1, 'condi_tionering': 1, 'versterking': 1, 'apparatuur': 1, 'analyselaboratoria': 1, 'apotheek': 1, 'subsidie': 3, 'overnachting': 1, 'administratie': 1, 'hoofd': 1, 'bewijsstukk': 1, 'regel': 1, 'uitvoering': 1}\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "#example for unsupervised function\n",
    "#########################################################\n",
    "# test with a file containing NL text\n",
    "#\n",
    "with open('../data/text.txt', encoding=\"utf8\") as file:\n",
    "    txt = file.read()\n",
    "#print(txt)\n",
    "dict_text=get_keywordsunsupervised(txt,0.9)\n",
    "print(\"TOPIC DOC {}:{}\\n\".format(0,dict_text))\n",
    "\n",
    "\n",
    "#example for unsupervised\n",
    "# test with a pandas NL text\n",
    "#\n",
    "df = pd.read_pickle(\"../data/Staatsblad_nl_fr.pkl\") \n",
    "#testing with txt at pos 100 en 101\n",
    "for i in range(2):\n",
    "    dict_text=get_keywordsunsupervised(df['cleantextnl'][i+100],0.90)\n",
    "    print(dict_text)\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS THE END FOR NOW ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f76d795eeeb227e2159e85f1e474be6be927cb377d2f5f811780d197b385e423"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
