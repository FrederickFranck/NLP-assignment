{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPMG analyse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!python -m spacy download nl_core_news_md\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load model\n",
    "nlp = spacy.load(\"nl_core_news_md\")\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some debugging stuff\n",
    "# \n",
    "if DEBUG:\n",
    "    import inspect \n",
    "    def getname():\n",
    "        import sys\n",
    "        return sys._getframe(1).f_code.co_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_cleanandlemmatize(txtdoc: str, list_wordstoskip:str = '', onlynouns:bool = True) -> (dict,list):\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "   \n",
    "    LANG='nl'\n",
    "    # words to discard\n",
    "    months={'nl':['januari','februari','maart','april','mei','juni','augustus','september','oktober','november','december'],\n",
    "            'fr':['janvier','fevrier','mars','avril','mai','juin','juillet','aout','septembre','octobre','decembre']}\n",
    "    days={'nl':['maandag','dinsdag','woensdag','donderdag','vrijdag','zaterdag','zondag'],\n",
    "            'fr':['lundi','mardi','mercredi','jeudi','vendredi','samedi','dimanche']}\n",
    "    # \n",
    "    nlp.max_length=10000000\n",
    "    nlp_doc=nlp(txtdoc)\n",
    "    list_allwordslemmatized=[]\n",
    "    dict_uniqwords={}\n",
    "    list_tokens=[]\n",
    "    #filter\n",
    "    for token in nlp_doc:\n",
    "        lemma_lower=token.lemma_.lower()\n",
    "        if token in stopwords:\n",
    "            continue\n",
    "        if (token.is_punct or token.is_space or token.is_stop):\n",
    "            continue\n",
    "        if token.text.isdecimal():\n",
    "            continue\n",
    "        if True in [char.isdigit() for char in token.text]:\n",
    "            continue\n",
    "        if token.text[-1] == '.':\n",
    "            continue\n",
    "        if len(token.text) <= 2:\n",
    "            continue\n",
    "        if lemma_lower in months[LANG]:\n",
    "            continue\n",
    "        if lemma_lower in days[LANG]:\n",
    "            continue\n",
    "        if lemma_lower in list_wordstoskip:\n",
    "            continue\n",
    "        #pass only nouns\n",
    "        if token.pos_ != 'NOUN':\n",
    "            continue\n",
    "        #create dict of unique words with count\n",
    "        if lemma_lower not in dict_uniqwords: \n",
    "            dict_uniqwords[lemma_lower]=1\n",
    "            #save tokens for vector comparison\n",
    "            list_tokens.append(token)\n",
    "        else:\n",
    "            dict_uniqwords[lemma_lower]+=1\n",
    "    return dict_uniqwords, list_tokens\n",
    "    #end of filter------------------------\n",
    "\n",
    "#compare a token against a tokenslist\n",
    "def token_compare(token_totest,list_tokens,min_score:int = 0.6):\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "    \n",
    "    #return list of tokens with similarity >= min_score \n",
    "    list_tokens_toreturn=[]\n",
    "    tot_similar_word=0\n",
    "    istax=False\n",
    "    for token in list_tokens:\n",
    "        similar=token_totest.similarity(token)\n",
    "        #only addup the scores >= min_score\n",
    "        if similar >= min_score:\n",
    "            list_tokens_toreturn.append([token_totest,token,similar])\n",
    "            #positive for tax\n",
    "            istax=True\n",
    "            tot_similar_word+=similar\n",
    "    return istax, tot_similar_word, list_tokens_toreturn\n",
    "\n",
    "def createlistofkeywords(numberofdocumenttoscan:int = 50,similar_doc:int = 0,min_score:float = 0.6, list_keywords:list = []) -> (list,list,list):\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "     \n",
    "    list_keep_tax_words=[]\n",
    "    list_keep_pointer_taxdocs=[]\n",
    "    list_keep_pointer_alldocs=[]\n",
    "\n",
    "    #take all docs if 0\n",
    "    if numberofdocumenttoscan == 0:\n",
    "        numberofdocumenttoscan=len(df)\n",
    "    \n",
    "    for n in range(numberofdocumenttoscan):\n",
    "\n",
    "        print(\"Documents analyzed: \",numberofdocumenttoscan,n)\n",
    "\n",
    "        txtdoc = df['cleantextnl'].values[n]\n",
    "        list_wordstoskip=['blabla','blablabla'] #add here words to discard\n",
    "        dict_uniqwords,list_tokens=nlp_cleanandlemmatize(txtdoc,list_wordstoskip) #get tokens\n",
    "\n",
    "        #tokenize and check\n",
    "        tot_similar_doc=0     #keep score for onlytax docs (istax=True)\n",
    "        tot_similar_doc_all=0 #keep score for all docs\n",
    "        istax_doc=False\n",
    "        \n",
    "        for word in list_keywords:\n",
    "            token_word = nlp(word)\n",
    "            istax, tot_similar_word, list_res_tokens=token_compare(token_word,list_tokens,min_score)\n",
    "            #if DEBUG: print(\"DEBUG\",istax, tot_similar_word, list_res_tokens)\n",
    "            tot_similar_doc_all+=tot_similar_word\n",
    "\n",
    "            if istax:\n",
    "                for taxtoken in list_res_tokens:\n",
    "                    if taxtoken[1].lemma_.lower() not in list_keep_tax_words:\n",
    "                        list_keep_tax_words.append(taxtoken[1].lemma_.lower())\n",
    "                tot_similar_doc+=tot_similar_word\n",
    "            istax_doc |= istax\n",
    "\n",
    "        #store score for all\n",
    "        list_keep_pointer_alldocs.append([n,tot_similar_doc_all])\n",
    "\n",
    "        #store score for taxdocs\n",
    "        if istax_doc and (tot_similar_doc >= similar_doc):\n",
    "            list_keep_pointer_taxdocs.append([n,tot_similar_doc])\n",
    "\n",
    "    return list_keep_pointer_taxdocs, list_keep_tax_words, list_keep_pointer_alldocs\n",
    "\n",
    "def create_pickle_keywords_and_docscores(list_keywords:list = ['belasting'], file_keywords:str = \"\", file_docscores:str = \"\")-> (list,list):\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "     \n",
    "    #settings : [numberofdocumenttoscan (0 for all), min similarity score for doc to get into the taxlist, min similarity score for keywords]):\n",
    "    settings=[  [5,5,0.97],    #step1\n",
    "                [10,10,0.95],  #step2\n",
    "                [15,20,0.90],  #step3\n",
    "                [0,40,0.87]    #step4 All documents\n",
    "                ]\n",
    "    \n",
    "    numberofsteps=len(settings)\n",
    "    for step in range(numberofsteps):\n",
    "        list_keep_pointer_taxdocs , list_keep_tax_words, list_keep_pointer_alldocs = createlistofkeywords(settings[step][0],settings[step][1],settings[step][2],list_keywords)\n",
    "        list_keywords+=list_keep_tax_words\n",
    "        #no duplicates\n",
    "        list_keywords = list(set(list_keywords))\n",
    "        list_docscores=list_keep_pointer_alldocs\n",
    "        \n",
    "        # no file no pickle\n",
    "        if file_keywords != \"\" :\n",
    "            df_keywords=pd.DataFrame(list_keywords,columns=['keywords'])\n",
    "            df_keywords.to_pickle(file_keywords)  \n",
    "            \n",
    "        if file_docscores != \"\"  :\n",
    "            df_docscores=pd.DataFrame(list_keep_pointer_alldocs,columns=['docpointer','docscores']) \n",
    "            df_docscores.to_pickle(file_docscores)  \n",
    "\n",
    "    return list_keywords, list_docscores\n",
    "\n",
    "def score_text(txt:str,language:str = 'nl', min_score:float = 0.3, file_keywords:str = \"../data/tax_keywords_nl.pkl\") -> float :\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "\n",
    "    if language == 'nl':\n",
    "        df_keywords = pd.read_pickle(file_keywords) \n",
    "        list_keywords=list(df_keywords['keywords'])\n",
    "        \n",
    "        #clean txt / get tokens\n",
    "        dict_uniqwords,list_tokens=nlp_cleanandlemmatize(txt,[]) \n",
    "        \n",
    "        docscore=0  \n",
    "        for word in list_keywords:\n",
    "            token_word = nlp(word)\n",
    "            for token in list_tokens:\n",
    "                similar=token_word.similarity(token)\n",
    "                #similarity > min_score to be taken into account\n",
    "                if similar >= min_score:\n",
    "                    docscore+=similar\n",
    "    else:\n",
    "        print(\"Language selection not supported for now!\")\n",
    "\n",
    "    return docscore\n",
    "\n",
    "def create_initial_keywordlist(language:str ='nl') -> None:\n",
    "    # create keyword list picklefile and docscores picklefile\n",
    "    #read all docs\n",
    "    global df\n",
    "    df = pd.read_pickle(\"../data/Staatsblad_nl_fr.pkl\") \n",
    "    if language == 'nl':\n",
    "        #start search for nl keywords\n",
    "        keywords, docscores = create_pickle_keywords_and_docscores(['belasting','tax','fisc'], \"../data/tax_keywords_nl.pkl\", \"../data/tax_docscores_nl.pkl\")\n",
    "    else:\n",
    "        print(\"Language selection not supported for now!\")\n",
    "\n",
    "\n",
    "#unsupervised keyword search\n",
    "def get_keywordsunsupervised(txt:str, sim:float = 0.90) -> dict:\n",
    "    # input a text \n",
    "    # output relevant keywords\n",
    "    doc = nlp(txt)\n",
    "\n",
    "    chnk=[]\n",
    "    for chunk in doc.noun_chunks:\n",
    "        chnk.append(chunk)\n",
    "\n",
    "    sim_low=sim\n",
    "    txt_keywords=''\n",
    "    list_keywordswithscores=[]\n",
    "    for c in chnk:\n",
    "        word_simil=0\n",
    "        for t in chnk:\n",
    "            simil=c.similarity(t)\n",
    "            if (simil >= sim_low and simil < 1): \n",
    "                word_simil+=simil\n",
    "                \n",
    "        if word_simil > 1:\n",
    "            list_keywordswithscores.append([c,word_simil])\n",
    "            txt_keywords=txt_keywords + c.lemma_ +' '\n",
    "            \n",
    "    dict_txt,list_tokens=nlp_cleanandlemmatize(txtdoc=txt_keywords,list_wordstoskip='',onlynouns=True)\n",
    "    return dict_txt\n",
    "\n",
    "def score_topic_list(txt:str,language:str = 'nl', min_score:float = 0.3, list_topics:list = ['belasting','tax']) -> float :\n",
    "    if DEBUG : print(\"In function: \",getname(), inspect.signature(globals()[getname()]))\n",
    "\n",
    "    if language == 'nl':\n",
    "       \n",
    "        #clean txt / get tokens\n",
    "        dict_uniqwords,list_tokens=nlp_cleanandlemmatize(txt,[]) \n",
    "\n",
    "        topic_score=[]\n",
    "       \n",
    "        for word in list_topics:\n",
    "            docscore=0\n",
    "            token_word = nlp(word)\n",
    "            for token in list_tokens:\n",
    "                similar=token_word.similarity(token)\n",
    "                #similarity > min_score to be taken into account\n",
    "                #print(similar)\n",
    "                if similar >= min_score:\n",
    "                    docscore+=similar\n",
    "            topic_score.append(docscore)\n",
    "            #print(\"@@@\",word,docscore)\n",
    "    else:\n",
    "        topic_score=[]\n",
    "        print(\"Language selection not supported for now!\")\n",
    "\n",
    "    return topic_score   \n",
    "\n",
    "\n",
    "def score_text_byvector(txt:str,language:str = 'nl', min_score:float = 0.3, file_keywords:str = \"../data/tax_keywords_nl.pkl\") -> float :\n",
    "    if language != 'nl':\n",
    "        print(\"Language selection not supported for now!\")\n",
    "        return -999\n",
    "\n",
    "    df_keywords = pd.read_pickle(file_keywords) \n",
    "    list_keywords=list(df_keywords['keywords'])\n",
    "\n",
    "    txt_keywords=''\n",
    "    for t in list_keywords: txt_keywords += ' ' + t\n",
    "    token_txt = nlp(txt_keywords)\n",
    "\n",
    "    #clean txt  \n",
    "    txt_doc=''\n",
    "    dict_uniqwords,list_tokens=nlp_cleanandlemmatize(txt,[]) \n",
    "    for i in list_tokens: txt_doc += ' ' + (i.lemma_).lower()\n",
    "    token_doc = nlp(txt_doc)\n",
    "\n",
    "    docscore=token_doc.similarity(token_txt)   \n",
    "\n",
    "    return docscore\n",
    "\n",
    "\n",
    "def get_topic_byvector(txt:str, language:str = 'nl') -> [float,str] :\n",
    "    if language != 'nl':\n",
    "        print(\"Language selection not supported for now!\")\n",
    "        return -999\n",
    "    list_topic_keywords = [ ['inkomstenbelasting'],\n",
    "                            ['personenbelasting'],\n",
    "                            ['vennootschapsbelasting'],\n",
    "                            ['rechtspersonenbelasting'],\n",
    "                            ['belasting van niet-inwoners'],\n",
    "                            ['belasting op de toegevoegde waarde'],\n",
    "                            ['internationale belastingrecht'],\n",
    "                            ['registratierechten'],\n",
    "                            ['successierechten'],\n",
    "                            ['douanerechten'],\n",
    "                            ['verkeersbelasting'],\n",
    "                            ['loonbelasting'],\n",
    "                            ['dividendbelasting'],\n",
    "                            ['erfbelasting'],\n",
    "                            ['schenkbelasting'],\n",
    "                            ['kansspelbelasting'],\n",
    "                            ['gokbelasting'],\n",
    "                            ['vermogensrendementsheffing']\n",
    "                            ]\n",
    "\n",
    "\n",
    "    #clean text  \n",
    "    txt_doc=''\n",
    "    dict_uniqwords,list_tokens=nlp_cleanandlemmatize(txt,[]) \n",
    "    for i in list_tokens: txt_doc += ' ' + (i.lemma_).lower()\n",
    "\n",
    "    #\n",
    "    topicscore=[]\n",
    "    for list_keywords in list_topic_keywords:\n",
    "        txt_keywords=''\n",
    "        for t in list_keywords: txt_keywords += ' ' + t\n",
    "        token_txt = nlp(txt_keywords)\n",
    "        token_doc = nlp(txt_doc)\n",
    "\n",
    "        topicscore.append([token_doc.similarity(token_txt),list_keywords])   \n",
    "        topicscore.sort(reverse=True)\n",
    "        score = topicscore[0]\n",
    "    return topicscore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create the inital keyword list (takes some time to run +-7min on my old laptop) and needs to be run only once!\n",
    "#df = pd.read_pickle(\"../data/Staatsblad_nl_fr.pkl\") \n",
    "\n",
    "#create_initial_keywordlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmadmin\\AppData\\Local\\Temp\\ipykernel_1140\\4258896363.py:294: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  topicscore.append([token_doc.similarity(token_txt),list_keywords])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc. nr: 0  --->>  [[0.7487207824085366, ['vennootschapsbelasting']], [0.7487207824085366, ['rechtspersonenbelasting']], [0.7487207824085366, ['dividendbelasting']], [0.7395439827552766, ['internationale belastingrecht']], [0.7247386939478287, ['vermogensrendementsheffing']], [0.7247386939478287, ['schenkbelasting']], [0.7247386939478287, ['personenbelasting']], [0.7247386939478287, ['loonbelasting']], [0.7247386939478287, ['kansspelbelasting']], [0.7247386939478287, ['inkomstenbelasting']], [0.7247386939478287, ['erfbelasting']], [0.7077180633342771, ['successierechten']], [0.6768987499247198, ['douanerechten']], [0.6589777626921278, ['registratierechten']], [0.6404529739562098, ['verkeersbelasting']], [0.6229665826607022, ['belasting van niet-inwoners']], [0.5645308553529333, ['belasting op de toegevoegde waarde']], [0.0, ['gokbelasting']]]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 1  --->>  [[0.6901101525735599, ['successierechten']], [0.686147257226492, ['vennootschapsbelasting']], [0.686147257226492, ['rechtspersonenbelasting']], [0.686147257226492, ['dividendbelasting']], [0.6767867970527526, ['registratierechten']], [0.6754726173805241, ['vermogensrendementsheffing']], [0.6754726173805241, ['schenkbelasting']], [0.6754726173805241, ['personenbelasting']], [0.6754726173805241, ['loonbelasting']], [0.6754726173805241, ['kansspelbelasting']], [0.6754726173805241, ['inkomstenbelasting']], [0.6754726173805241, ['erfbelasting']], [0.6690303493554342, ['douanerechten']], [0.6659515960892417, ['internationale belastingrecht']], [0.6261573410478103, ['verkeersbelasting']], [0.538156591536086, ['belasting van niet-inwoners']], [0.5111875660119544, ['belasting op de toegevoegde waarde']], [0.0, ['gokbelasting']]]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 2  --->>  [[0.4549312785212403, ['registratierechten']], [0.43066058015452735, ['douanerechten']], [0.4299323712694292, ['successierechten']], [0.3952849913001157, ['internationale belastingrecht']], [0.3727578343819438, ['vennootschapsbelasting']], [0.3727578343819438, ['rechtspersonenbelasting']], [0.3727578343819438, ['dividendbelasting']], [0.37153711929751754, ['vermogensrendementsheffing']], [0.37153711929751754, ['schenkbelasting']], [0.37153711929751754, ['personenbelasting']], [0.37153711929751754, ['loonbelasting']], [0.37153711929751754, ['kansspelbelasting']], [0.37153711929751754, ['inkomstenbelasting']], [0.37153711929751754, ['erfbelasting']], [0.34395144113069487, ['verkeersbelasting']], [0.28005754660110144, ['belasting van niet-inwoners']], [0.2655978953862501, ['belasting op de toegevoegde waarde']], [0.0, ['gokbelasting']]]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 3  --->>  [[0.7398864433592595, ['internationale belastingrecht']], [0.6891263229748346, ['vennootschapsbelasting']], [0.6891263229748346, ['rechtspersonenbelasting']], [0.6891263229748346, ['dividendbelasting']], [0.667493554709373, ['successierechten']], [0.6670082018439555, ['registratierechten']], [0.662670368252435, ['vermogensrendementsheffing']], [0.662670368252435, ['schenkbelasting']], [0.662670368252435, ['personenbelasting']], [0.662670368252435, ['loonbelasting']], [0.662670368252435, ['kansspelbelasting']], [0.662670368252435, ['inkomstenbelasting']], [0.662670368252435, ['erfbelasting']], [0.6186673315231719, ['douanerechten']], [0.5981971182954946, ['belasting van niet-inwoners']], [0.5892425348344431, ['verkeersbelasting']], [0.5345628711978183, ['belasting op de toegevoegde waarde']], [0.0, ['gokbelasting']]]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 4  --->>  [[0.7552442384831771, ['vennootschapsbelasting']], [0.7552442384831771, ['rechtspersonenbelasting']], [0.7552442384831771, ['dividendbelasting']], [0.7534015611415584, ['successierechten']], [0.7437678433833793, ['vermogensrendementsheffing']], [0.7437678433833793, ['schenkbelasting']], [0.7437678433833793, ['personenbelasting']], [0.7437678433833793, ['loonbelasting']], [0.7437678433833793, ['kansspelbelasting']], [0.7437678433833793, ['inkomstenbelasting']], [0.7437678433833793, ['erfbelasting']], [0.7402915115627026, ['internationale belastingrecht']], [0.7203079674790733, ['douanerechten']], [0.6898590465958182, ['verkeersbelasting']], [0.6857480261456065, ['registratierechten']], [0.6338774250575854, ['belasting van niet-inwoners']], [0.5896768718538138, ['belasting op de toegevoegde waarde']], [0.0, ['gokbelasting']]]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 5  --->>  [[0.7532072980154575, ['vennootschapsbelasting']], [0.7532072980154575, ['rechtspersonenbelasting']], [0.7532072980154575, ['dividendbelasting']], [0.7378182438721491, ['successierechten']], [0.7320653338295752, ['vermogensrendementsheffing']], [0.7320653338295752, ['schenkbelasting']], [0.7320653338295752, ['personenbelasting']], [0.7320653338295752, ['loonbelasting']], [0.7320653338295752, ['kansspelbelasting']], [0.7320653338295752, ['inkomstenbelasting']], [0.7320653338295752, ['erfbelasting']], [0.7306971476561817, ['internationale belastingrecht']], [0.7137485641169149, ['douanerechten']], [0.6714239207039222, ['verkeersbelasting']], [0.668499201383641, ['registratierechten']], [0.6186042276356024, ['belasting van niet-inwoners']], [0.5780009859631853, ['belasting op de toegevoegde waarde']], [0.0, ['gokbelasting']]]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 6  --->>  [[0.7793690473749172, ['vermogensrendementsheffing']], [0.7793690473749172, ['schenkbelasting']], [0.7793690473749172, ['personenbelasting']], [0.7793690473749172, ['loonbelasting']], [0.7793690473749172, ['kansspelbelasting']], [0.7793690473749172, ['inkomstenbelasting']], [0.7793690473749172, ['erfbelasting']], [0.7773309571876315, ['successierechten']], [0.7717531553320294, ['vennootschapsbelasting']], [0.7717531553320294, ['rechtspersonenbelasting']], [0.7717531553320294, ['dividendbelasting']], [0.7573277292090793, ['internationale belastingrecht']], [0.7264509465021657, ['verkeersbelasting']], [0.7228505221788515, ['douanerechten']], [0.7186645351231031, ['registratierechten']], [0.6661044276320931, ['belasting van niet-inwoners']], [0.6214691709159421, ['belasting op de toegevoegde waarde']], [0.0, ['gokbelasting']]]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 7  --->>  [[0.7524580376003799, ['internationale belastingrecht']], [0.6992727568897315, ['vennootschapsbelasting']], [0.6992727568897315, ['rechtspersonenbelasting']], [0.6992727568897315, ['dividendbelasting']], [0.6801788809694183, ['registratierechten']], [0.6794459807989824, ['successierechten']], [0.673979265829334, ['vermogensrendementsheffing']], [0.673979265829334, ['schenkbelasting']], [0.673979265829334, ['personenbelasting']], [0.673979265829334, ['loonbelasting']], [0.673979265829334, ['kansspelbelasting']], [0.673979265829334, ['inkomstenbelasting']], [0.673979265829334, ['erfbelasting']], [0.6327763248216499, ['douanerechten']], [0.6125864589684776, ['belasting van niet-inwoners']], [0.6001601996395128, ['verkeersbelasting']], [0.5492907986955748, ['belasting op de toegevoegde waarde']], [0.0, ['gokbelasting']]]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 8  --->>  [[0.7162664326227041, ['vennootschapsbelasting']], [0.7162664326227041, ['rechtspersonenbelasting']], [0.7162664326227041, ['dividendbelasting']], [0.6993123593418035, ['vermogensrendementsheffing']], [0.6993123593418035, ['schenkbelasting']], [0.6993123593418035, ['personenbelasting']], [0.6993123593418035, ['loonbelasting']], [0.6993123593418035, ['kansspelbelasting']], [0.6993123593418035, ['inkomstenbelasting']], [0.6993123593418035, ['erfbelasting']], [0.6834481673064721, ['internationale belastingrecht']], [0.6643013616845709, ['successierechten']], [0.6566211631855201, ['douanerechten']], [0.6300840428786083, ['registratierechten']], [0.6033687191110634, ['verkeersbelasting']], [0.5821253122181513, ['belasting van niet-inwoners']], [0.5453375303018874, ['belasting op de toegevoegde waarde']], [0.0, ['gokbelasting']]]\n",
      "------------------------------------------------------\n",
      "Doc. nr: 9  --->>  [[0.6321006821287842, ['vennootschapsbelasting']], [0.6321006821287842, ['rechtspersonenbelasting']], [0.6321006821287842, ['dividendbelasting']], [0.6056396237672799, ['vermogensrendementsheffing']], [0.6056396237672799, ['schenkbelasting']], [0.6056396237672799, ['personenbelasting']], [0.6056396237672799, ['loonbelasting']], [0.6056396237672799, ['kansspelbelasting']], [0.6056396237672799, ['inkomstenbelasting']], [0.6056396237672799, ['erfbelasting']], [0.5988482686236164, ['internationale belastingrecht']], [0.567483055461804, ['douanerechten']], [0.5655894779255191, ['successierechten']], [0.5370220231260917, ['registratierechten']], [0.49204191724550334, ['verkeersbelasting']], [0.4783563854828098, ['belasting van niet-inwoners']], [0.4579646928806376, ['belasting op de toegevoegde waarde']], [0.0, ['gokbelasting']]]\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Example usage for get_topic_byvector\n",
    "df = pd.read_pickle(\"../data/Staatsblad.pkl\") \n",
    "\n",
    "for loop in range(10):\n",
    "    txt=df['cleantextnl'][loop]\n",
    "    topicscore=get_topic_byvector(txt)\n",
    "\n",
    "    #topic.sort(reverse=True)\n",
    "    print(\"Doc. nr:\",loop,\" --->> \",topicscore)\n",
    "    print('------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for d: 2.9043948372239012 score for d2: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmadmin\\AppData\\Local\\Temp\\ipykernel_8804\\257392022.py:157: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  similar=token_word.similarity(token)\n"
     ]
    }
   ],
   "source": [
    "#Get score for one txt string\n",
    "#############################\n",
    "#This will use the pickled keyword list created by the create_initial_keywordlist() function\n",
    "txt='de belastingen zijn er weer\\n Deze tax keer meer belastingen en meer tax te betalen!\\n meer en meer belastingen tax is nodig en fisc'\n",
    "txt2='this text does not contain any ... related words\\n '\n",
    "d = score_text(txt)\n",
    "d2 = score_text(txt2)\n",
    "print(\"score for d:\",d,\"score for d2:\",d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC DOC 0:{'houdbaarheidsdatum': 2, 'bewoner': 1, 'applicatie': 1, 'medewerker': 1, 'koffiekoek': 1, 'reactie': 1, 'overschot': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmadmin\\AppData\\Local\\Temp\\ipykernel_8804\\257392022.py:194: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
      "  simil=c.similarity(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'onder_wijswetgeving': 1, 'onderwijs': 9, 'artikel': 3, 'regering': 12, 'voorwaarde': 3, 'organisatie': 8, 'onderwijsactiviteit': 2, 'studie': 7, 'type': 7, 'inspecteur': 1, 'akkoordbevinding': 1, 'minister': 2, 'lid': 17, 'wet': 1, 'opschorting': 1, 'noodzakelijkheid': 3, 'vast_stellen': 1, 'maatregel': 3, 'aandacht': 1, 'instelling': 5, 'omzendbrief': 2, 'nummer': 1, 'aanneming': 1, 'voordracht': 1, 'gezondheidscrisis': 1, 'regeling': 2, 'student': 7, 'onderwijseenheden': 1, 'einddatum': 1, 'eenheid': 1, 'lesti_jd': 1, 'lestijd': 1, 'punt': 1, 'ond_erwijswetgeving': 1, 'herinsc_hrijving': 1, 'onderwijseenhed': 1, 'opsluiting': 1, 'zitting': 3, 'onderwijsinstelling': 2, 'paragraaf': 1, 'evaluatie': 8, 'leerresultaten': 3, 'directie': 2, 'toelating': 2, 'lee_rresultat': 2, 'nazicht': 2, 'onderwijseenheid': 2, 'regel': 3, 'plan': 1, 'evaluatiedatum': 1, 'aard': 1, 'kenmerk': 1, 'materieel': 1, 'omstandigheid': 1, 'mededeling': 1, 'beoordeling': 1, 'eindevaluatie': 2, 'begind_atum': 3, 'startdatum': 1, 'certificatie': 2, 'noemen': 1, 'uitvoering': 1}\n",
      "-----------------------\n",
      "{'steun': 1, 'ziekenhuis': 12, 'artikel': 5, 'financiering': 1, 'dienst': 1, 'regering': 7, 'inspecteur': 1, 'akkoordbevinding': 1, 'minister': 6, 'beleid_lijnen': 1, 'verspreiding': 1, 'bevoegdheid': 2, 'gevolg': 1, 'decreet': 1, 'uitoefening': 1, 'oprichting': 2, 'toename': 1, 'afdeling': 2, 'organisatie': 1, 'opname': 1, 'mobilisatie': 1, 'noodzaak': 1, 'bestrijding': 1, 'voordracht': 1, 'ziekenhuizen': 1, 'voorwaarde': 2, 'toekenning': 2, 'opdracht': 1, 'uitgave': 1, 'inrichting': 1, 'aanpassing': 1, 'opvang': 2, 'ziekenhuisopname': 2, 'aankoop': 1, 'uit_rusting': 1, 'condi_tionering': 1, 'versterking': 1, 'apparatuur': 1, 'analyselaboratoria': 1, 'apotheek': 1, 'subsidie': 3, 'overnachting': 1, 'administratie': 1, 'hoofd': 1, 'bewijsstukk': 1, 'regel': 1, 'uitvoering': 1}\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "#example for unsupervised function\n",
    "#########################################################\n",
    "# test with a file containing NL text\n",
    "#\n",
    "with open('../data/text.txt', encoding=\"utf8\") as file:\n",
    "    txt = file.read()\n",
    "#print(txt)\n",
    "dict_text=get_keywordsunsupervised(txt,0.9)\n",
    "print(\"TOPIC DOC {}:{}\\n\".format(0,dict_text))\n",
    "\n",
    "\n",
    "#example for unsupervised\n",
    "# test with a pandas NL text\n",
    "#\n",
    "df = pd.read_pickle(\"../data/Staatsblad_nl_fr.pkl\") \n",
    "#testing with txt at pos 100 en 101\n",
    "for i in range(2):\n",
    "    dict_text=get_keywordsunsupervised(df['cleantextnl'][i+100],0.90)\n",
    "    print(dict_text)\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS THE END FOR NOW ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f76d795eeeb227e2159e85f1e474be6be927cb377d2f5f811780d197b385e423"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
